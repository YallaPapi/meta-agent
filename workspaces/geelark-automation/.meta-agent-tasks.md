# Meta-Agent Implementation Tasks

## Instructions for Claude Code

This file contains implementation tasks identified by meta-agent analysis.

### IMPORTANT: Use Taskmaster for Implementation

**You MUST use Taskmaster to implement these tasks.** Do NOT manage tasks manually.

To import these tasks into Taskmaster:
```bash
# Parse this file as a PRD to add tasks to Taskmaster
task-master parse-prd .meta-agent-tasks.md --append

# Then work through tasks using Taskmaster commands:
task-master list                    # See all tasks
task-master next                    # Get next task to work on
task-master set-status --id=<id> --status=in-progress
task-master set-status --id=<id> --status=done
```

### Task Workflow:
1. Import tasks into Taskmaster using `parse-prd --append`
2. Use `task-master next` to get the highest priority task
3. Mark task as `in-progress` before starting
4. Implement the task following the description below
5. Mark task as `done` when complete
6. Commit changes after completing related tasks

---

## Task Summary

- **Critical:** 5 task(s)
- **High:** 2 task(s)
- **Medium:** 1 task(s)
- **Total:** 8 task(s)

---

## Tasks

### 1. ðŸ”´ Create project scaffold with all PRD files

- [ ] **Status:** Not started
- **Priority:** Critical
- **File:** `geelark-automation/ (all files)`

**Description:**

Create empty Python files matching exact PRD structure: dm_bot.py, stage_analyzer.py, response_generator.py, funnel_stages.py, conversation_state.py, persona_config.py, response_variety.py, delay_calculator.py, photo_manager.py, metrics.py, errors.py. Add __init__.py files for packages. Create config.yaml with placeholder persona/OF_link.

### 2. ðŸ”´ Implement basic config loading

- [ ] **Status:** Not started
- **Priority:** Critical
- **File:** `persona_config.py`

**Description:**

In persona_config.py: Load config.yaml with YAML library. Define Persona dataclass matching PRD schema. Add load_persona() function that returns Persona object. Test with sample Mia persona.

### 3. ðŸ”´ Create conversation state model

- [ ] **Status:** Not started
- **Priority:** Critical
- **File:** `conversation_state.py`

**Description:**

In conversation_state.py: Define ConversationState dataclass/Pydantic model matching EXACT PRD JSON schema (user_id, history, funnel_stage, location_mentioned, etc). Implement load_state(user_id), save_state(state), get_or_create_state(user_id) functions using JSON files (user_id.json).

### 4. ðŸ”´ Skeleton LLM client wrapper

- [ ] **Status:** Not started
- **Priority:** Critical
- **File:** `llm_client.py`

**Description:**

Create llm_client.py with OllamaClient class. Implement call_llm(prompt: str, model: str) -> str. Add parse_json_response(response: str, schema: dict) -> dict with basic error handling. Support both stage_analyzer and response_generator schemas.

### 5. ðŸ”´ Main orchestrator skeleton

- [ ] **Status:** Not started
- **Priority:** Critical
- **File:** `dm_bot.py`

**Description:**

In dm_bot.py: Implement process_message(user_id: str, user_message: str) -> dict. Skeleton: load_state -> call stage_analyzer -> update_state -> call response_generator -> return response dict. No real LLM calls yet - mock outputs matching PRD JSON schemas.

### 6. ðŸŸ  Define funnel stages enum

- [ ] **Status:** Not started
- **Priority:** High
- **File:** `funnel_stages.py`

**Description:**

In funnel_stages.py: Create FunnelStage Enum with all 9 stages exactly as PRD (initial_response, small_talk, etc). Add get_stage_guidelines(stage: FunnelStage) -> str that returns PRD stage description/examples for LLM prompts.

### 7. ðŸŸ  Add requirements.txt and basic setup

- [ ] **Status:** Not started
- **Priority:** High
- **File:** `requirements.txt, pyproject.toml`

**Description:**

Create requirements.txt with pydantic, pyYAML, ollama, dataclasses-json. Add setup.py or pyproject.toml. Create basic run.py that imports dm_bot and prints 'Scaffold ready'.

### 8. ðŸŸ¡ Basic logging setup

- [ ] **Status:** Not started
- **Priority:** Medium
- **File:** `dm_bot.py`

**Description:**

Configure structured logging in dm_bot.py for conversation_id, user_id, stage transitions, LLM calls. Log all inputs/outputs to JSON files for debugging.
